{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### json"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd78d1878fdd6211"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path = \"/data/data_full.json\"\n",
    "\n",
    "with open(file_path, 'r') as json_file:\n",
    "    data = json.load(json_file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6d5fa08bd254126"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for identifier, item in data.items():\n",
    "    try:\n",
    "        condition = item[\"log\"][\"condition\"]\n",
    "        date = item[\"date\"]\n",
    "        preference = item[\"log\"][\"preference\"]\n",
    "        age = item[\"log\"][\"age\"]\n",
    "        gender = item[\"log\"]['gender']\n",
    "        ux_list = item[\"log\"][\"ux\"]\n",
    "        for i, ux in enumerate(ux_list, start=1):\n",
    "            row = {\"identifier\": identifier, \"condition\": condition, \"preference\": preference, \"date\": date, \"age\": age, \"gender\": gender}\n",
    "            for j in range(1, 11):\n",
    "                key = f\"ux{j}\"\n",
    "                if key in ux:\n",
    "                    row[f\"ux{j}_{i}\"] = ux[key]\n",
    "                else:\n",
    "                    row[f\"ux{j}_{i}\"] = None\n",
    "            data_list.append(row)\n",
    "    except KeyError:\n",
    "        print(f\"Skipping identifier {identifier} due to missing keys or empty 'ux' list.\")\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.loc[df['date'] >= '2023-08-10']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "756e51ad11e3b846"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.groupby(['identifier', 'condition', 'preference', 'date', 'age', 'gender']).apply(lambda x: x.ffill().bfill())\n",
    "df = df.drop_duplicates(subset=['identifier', 'condition', 'preference', 'date', 'age', 'gender'])\n",
    "df.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "969803dc8904ff9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filtering the person who did not pay attention to anything\n",
    "df = df[df['identifier'] != \"5689069036109824\"]\n",
    "\n",
    "#filtering people with a mean 'cer' higher than 0.05 (identified in the main analysis)\n",
    "identifiers_to_exclude = ['5689069036109824', '5139174843744256', '5672404563001344', '5699843028680704', '5748214695198720', '5751095477403648']\n",
    "df = df[~df['identifier'].isin(identifiers_to_exclude)]\n",
    "df.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d099beba9750a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df['gender'].value_counts())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d2fd54bef4c683b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sus"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "877f76c2d75d8510"
  },
  {
   "cell_type": "markdown",
   "source": [
    "System Usability Scale score:\n",
    "- For each of the odd numbered questions, subtract 1 from the score.\n",
    "- For each of the even numbered questions, subtract their value from 5.\n",
    "- Take these new values which you have found, and add up the total score. Then multiply this by 2.5."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1aff4275dacc1a25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sus_1\n",
    "ux_cols_1 = ['ux1_1', 'ux2_1', 'ux3_1', 'ux4_1', 'ux5_1', 'ux6_1', 'ux7_1', 'ux8_1', 'ux9_1', 'ux10_1']\n",
    "odd_ux_cols_1 = ux_cols_1[::2]  # odd\n",
    "even_ux_cols_1 = ux_cols_1[1::2]  # even\n",
    "\n",
    "df['sus_1'] = df[odd_ux_cols_1].apply(lambda x: x - 1).sum(axis=1) + df[even_ux_cols_1].apply(lambda x: 5 - x).sum(axis=1) # subtract 1 from odd-numbered questions and subtract from 5 for even-numbered questions\n",
    "df['sus_1'] = df['sus_1'] * 2.5 # multiply the total score by 2.5\n",
    "\n",
    "# sus_2\n",
    "ux_cols_2 = ['ux1_2', 'ux2_2', 'ux3_2', 'ux4_2', 'ux5_2', 'ux6_2', 'ux7_2', 'ux8_2', 'ux9_2', 'ux10_2']\n",
    "odd_ux_cols_2 = ux_cols_2[::2]  # odd\n",
    "even_ux_cols_2 = ux_cols_2[1::2]  # even\n",
    "\n",
    "df['sus_2'] = df[odd_ux_cols_2].apply(lambda x: x - 1).sum(axis = 1) + df[even_ux_cols_2].apply(lambda x: 5 - x).sum(axis=1)\n",
    "df['sus_2'] = df['sus_2'] * 2.5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d21e3b5674800f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['sus_cognitive'] = df.apply(lambda row: row['sus_1'] if row['condition'] == 0 else row['sus_2'], axis=1)\n",
    "df['sus_baseline'] = df.apply(lambda row: row['sus_1'] if row['condition'] == 1 else row['sus_2'], axis=1)\n",
    "\n",
    "df = df[['identifier', 'condition', 'preference', 'sus_cognitive', 'sus_baseline']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb95e760cd3b76a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tests"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7705ca9db775854"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.histplot(data=df, x='sus_cognitive', kde=True, bins=10)\n",
    "plt.title('Distribution of SUS Cognitive Scores')\n",
    "plt.xlabel('SUS Cognitive Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fc6eac848467acf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x='sus_baseline', kde=True, bins=10)\n",
    "plt.title('Distribution of SUS Baseline Scores')\n",
    "plt.xlabel('SUS Baseline Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44aec44a1656c61c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Perform the paired t-test\n",
    "t_stat, p_value = ttest_rel(df['sus_cognitive'], df['sus_baseline'])\n",
    "\n",
    "# Calculate degrees of freedom\n",
    "degrees_of_freedom_1 = len(df['sus_cognitive']) - 1\n",
    "\n",
    "print(\"Paired t-test results:\")\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "print(\"Degrees of Freedom (df1):\", degrees_of_freedom_1)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    if t_stat > 0:\n",
    "        print(\"Cognitive group has a significantly higher mean.\")\n",
    "    else:\n",
    "        print(\"Baseline group has a significantly higher mean.\")\n",
    "else:\n",
    "    print(\"No significant difference between groups.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb445386b6c34aa9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['sus_cognitive'].describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99ed2ee95791bf6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['sus_baseline'].describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5be47e293780525"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preference_counts = df['preference'].value_counts()\n",
    "total_count = len(df)\n",
    "percentages = (preference_counts / total_count) * 100\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(x='preference', data=df, palette='Set2')\n",
    "ax.set_title('Preference Comparison')\n",
    "ax.set_xlabel('Preference')\n",
    "ax.set_ylabel('Percentage')\n",
    "\n",
    "for p, percentage in zip(ax.patches, percentages):\n",
    "    ax.annotate(f'{percentage:.2f}%', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', fontsize=12, color='black', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c0bf2760697854d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "count_1 = preference_counts[1]\n",
    "count_0 = preference_counts[0]\n",
    "nobs = len(df['preference'])\n",
    "z_stat, p_value = sm.stats.proportions_ztest([count_1, count_0], [nobs, nobs])\n",
    "\n",
    "# Display the results of the proportion test\n",
    "print(\"\\nProportion Test Results:\")\n",
    "print(\"Z-statistic:\", z_stat)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Determine significance at a chosen alpha level (e.g., 0.05)\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\nReject the null hypothesis: The proportions are significantly different.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis: The proportions are not significantly different.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e961a2717bdc6e6d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_csv('df_sus.csv', index = False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d426497817b28277"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
